{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import unittest\n",
    "import json\n",
    "import requests\n",
    "import pickle\n",
    "import logging\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Photo():\n",
    "    def __init__(self, title, author, tags):\n",
    "        self.title = title\n",
    "        self.author = author\n",
    "        self.tags = tags\n",
    "    def __str__(self):\n",
    "        return \"({}, {}, {})\".format(self.title, self.author, self.tags)\n",
    "\n",
    "my_photo = Photo(\"Photo1\", \"Ansel Adams\", ['Nature', 'Mist', 'Mountain'])\n",
    "\n",
    "#print my_photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open(\"sample_d.txt\", \"r\")\n",
    "sample_d = json.loads(f.read())\n",
    "f.close()\n",
    "\n",
    "#print sample_d['photo']['title']['_content']\n",
    "#print sample_d['photo']['owner']['username']\n",
    "#print sample_d['photo']['tags']['tag'][0]['_content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your job is to fill in the __init__ method\n",
    "class Photo2():\n",
    "    def __init__(self, photo_d):\n",
    "        self.title = (photo_d['photo']['title']['_content']).encode('utf-8')\n",
    "        self.author = (photo_d['photo']['owner']['username']).encode('utf-8')\n",
    "        self.tags = [(x['raw']).encode('utf-8') for x in photo_d['photo']['tags']['tag']]\n",
    "    def __repr__(self):   #using the special __repr__ method for later \n",
    "        return \"({}, {}, {})\".format(self.title, self.author, self.tags)\n",
    "    #def __getitem__(self, item):\n",
    "        #return self.item\n",
    "\n",
    "#print Photo2(sample_d), type (Photo2(sample_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flickr_key = '88c582e55511629d1c00f987981f5a6f' # paste your flickr key here, so the variable flickr_key contains a string (your flickr key!)\n",
    "if not flickr_key:\n",
    "    flickr_key = raw_input(\"Enter your flickr API key, or paste it in the .py file to avoid this prompt in the future: \\n>>\")\n",
    "\n",
    "\n",
    "cache_fname = \"cache.bin\"\n",
    "\n",
    "#loading contents in cache file to variable saved_cache\n",
    "try:\n",
    "    fobj = open(cache_fname, 'rb')\n",
    "    saved_cache = pickle.load(fobj)\n",
    "    fobj.close()\n",
    "except:\n",
    "    raise Exception(\"Cache file not found.\")\n",
    "\n",
    "\n",
    "def requestURL(baseurl, params = {}):\n",
    "    req = requests.Request(method = 'GET', url = baseurl, params = params)\n",
    "    prepped = req.prepare()\n",
    "    return prepped.url\n",
    "\n",
    "def get_with_caching(base_url, params_diction, cache_diction, cache_fname, omitted_keys = ['api_key']):\n",
    "    filtered_params_diction = {}\n",
    "    for k in params_diction:\n",
    "        if k not in omitted_keys:\n",
    "            filtered_params_diction[k] = params_diction[k]\n",
    "    full_url = requestURL(base_url, filtered_params_diction)\n",
    "    #print full_url\n",
    "    # step 1\n",
    "    if full_url in cache_diction:\n",
    "        # step 2\n",
    "        logging.info(\"retrieving cached result for \" + full_url)\n",
    "        return cache_diction[full_url]\n",
    "        #print cache_diction[full_url]\n",
    "    else:\n",
    "        # step 3\n",
    "        response = requests.get(base_url, params=params_diction)\n",
    "        logging.info(\"adding cached result for \" + full_url)\n",
    "        # add to the cache and save it permanently\n",
    "        cache_diction[full_url] = response.text\n",
    "        fobj = open(cache_fname, \"wb\")\n",
    "        pickle.dump(cache_diction, fobj)\n",
    "        fobj.close()\n",
    "        return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# [PROBLEM 3]\n",
    "\n",
    "# Get a response from flickr: data for 50 photos that are tagged with 'sunset'. \n",
    "#Store the list of dictionaries in a variable called search_result_txt. \n",
    "#See the textbook section on the flickr API, \n",
    "#and see the documentation page at https://www.flickr.com/services/api/flickr.photos.search.html\n",
    "\n",
    "params_d = {}\n",
    "params_d['method'] = 'flickr.photos.search'\n",
    "params_d['api_key'] = flickr_key\n",
    "params_d['format'] = 'json'\n",
    "params_d['tags'] = 'sunset'\n",
    "params_d['per_page'] = 50\n",
    "search_result_txt = get_with_caching('https://api.flickr.com/services/rest/', params_diction= params_d, \n",
    "                                     cache_diction = saved_cache, cache_fname = cache_fname)\n",
    "#print type(search_result_txt)\n",
    "#print search_result_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# [PROBLEM 4] Extract and parse as json\n",
    "\n",
    "# search_result contains a long string, \n",
    "#with the annoying extra characters that the flickr api adds at the beginning and end of its response text. \n",
    "#Strip off the extra characters and turn the remaining json-formatted text string into a python dictionary. \n",
    "#(Hint: see the flickr section of the UsingRESTAPIs chapter for a  reminder of how to do this.) \n",
    "#Save the dictionary in a variable called search_result_diction\n",
    "\n",
    "#this is my solution solving the \"unicode\" issue without involking json.loads.\n",
    "import ast    #converted parsed search_result_txt to a dict\n",
    "search_result_diction = ast.literal_eval(search_result_txt[14:-1])\n",
    "\n",
    "#print search_result_diction\n",
    "#print type(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# [PROBLEM 5] Extract a list of photo ids from the dictionary. Use a list comprehension or a call to map in order to do this.\n",
    "\n",
    "# REF: Read the chapter titled: \"More on Accumulation: Map, Filter, Reduce, List Comprehensions, and Zip\"\n",
    "\n",
    "photo_ids_list = [x['id'].encode('utf-8') for x in search_result_diction['photos']['photo']]\n",
    "#print photo_ids_list[0]\n",
    "#print photo_ids_list, type(photo_ids_list), type(photo_ids_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# [PROBLEM 6] Get info from flickr about each photo id\n",
    "\n",
    "## Create an instance of Photo2 for each of the photo ids.\n",
    "\n",
    "#a) make a request to the flickr API method flickr.photos.getInfo instead of flickr.photos.search. \n",
    "#See documentation at https://www.flickr.com/services/api/flickr.photos.getInfo.html for what to pass as extra parameters.\n",
    "#b) Extract a dictionary from the response for each.\n",
    "#c) Pass the dictionary when constructing a new instance of Photo2\n",
    "#d) Accumulate the instance into a list, called photo_instances\n",
    "\n",
    "def get_id_info(id):\n",
    "    params_d_id = {}\n",
    "    params_d_id['method'] = 'flickr.photos.getInfo'\n",
    "    params_d_id['api_key'] = flickr_key\n",
    "    params_d_id['format'] = 'json'\n",
    "    params_d_id['photo_id'] = id\n",
    "    search_result_diction_id = json.loads(get_with_caching('https://api.flickr.com/services/rest/', params_diction= params_d_id, \n",
    "                                     cache_diction = saved_cache, cache_fname = cache_fname)[14:-1])\n",
    "    #search_result_diction_id ={str(key):value for key,value in search_result_diction_id.items()}  \n",
    "    #above is my failed attempt to convert the dictionary to the one with unicode values\n",
    "    instance = Photo2(search_result_diction_id)\n",
    "    return instance\n",
    "photo_instances = [get_id_info(x) for x in photo_ids_list]\n",
    "\n",
    "#print type(photo_instances)\n",
    "#print photo_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# [PROBLEM 7] Accumulate frequencies of related tags.\n",
    "# You started out with data about 50 different photos, including the tags that the photo owners used to describe the photos. \n",
    "#They all have the tag 'sunset', since that's the tag we searched for, \n",
    "#but some have additional tags, like 'river' and 'nature' and others. \n",
    "#Accumulate a dictionary of counts; call the dictionary counts_diction.\n",
    "\n",
    "# REF: See the chapter titled, \"Accumulating Results in Dictionaries\"\n",
    "\n",
    "# getting all tags into a list\n",
    "counts_list = [x.tags for x in photo_instances]\n",
    "\n",
    "def get_elements(counts_list):  #flatten out the nested list 'counts_list'\n",
    "    counts_list_tag = []\n",
    "    for i in counts_list:\n",
    "        if type(i) == list:\n",
    "            counts_list_tag.extend(get_elements(i))\n",
    "        else:\n",
    "            counts_list_tag.append(i)\n",
    "    return counts_list_tag\n",
    "\n",
    "my_list = get_elements(counts_list)\n",
    "\n",
    "# counting the tags\n",
    "counts_diction = {} \n",
    "for i in my_list:\n",
    "    if i not in counts_diction:\n",
    "        counts_diction[i] = 1\n",
    "    else:\n",
    "        counts_diction[i] += 1\n",
    "\n",
    "#print counts_diction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# [PROBLEM 8] Sort the tags\n",
    "\n",
    "# Sort all the tags in descending order based on how often they were used in the 50 photos. \n",
    "#Save the sorted list in a variable called sorted_tags.\n",
    "\n",
    "# REF: See the chapter titled, \"Sorting\"\n",
    "\n",
    "sorted_tags = sorted(counts_diction.keys(), key=lambda x: counts_diction[x], reverse=True)\n",
    "\n",
    "#print type(sorted_tags)\n",
    "#print sorted_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below this line, the 5 most frequently used tags should print out:\n",
      "1. Lake Geneva\n",
      "2. Andrew Wilson Switzerland\n",
      "3. Lausanne\n",
      "4. Switzerland\n",
      "5. Sunset\n",
      "-----------------done; output of diagnostic tests is below this line------------\n"
     ]
    }
   ],
   "source": [
    "# [PROBLEM 9] Output five recommended tags\n",
    "\n",
    "\n",
    "## Print, for the user to see, the five tags (other than the searched on tag, sunset) that were used MOST frequently!\n",
    "\n",
    "## HINT 1: Take a slice of the sorted list.\n",
    "## HINT 2: Skip the first element in the sorted list. That will be \"sunset\", since all the photos have that tag.\n",
    "\n",
    "# REF: Slicing is in one of the early chapters, titled, \"Sequences\"\n",
    "\n",
    "print \"Below this line, the 5 most frequently used tags should print out:\"\n",
    "\n",
    "n = 0 #counter\n",
    "recommended_list = sorted_tags[1:6]\n",
    "for i in recommended_list:\n",
    "    n += 1\n",
    "    print \"{}. {}\".format(n, i)\n",
    "\n",
    "print \"-----------------done; output of diagnostic tests is below this line------------\""
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
